{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using FABRIC GPUs\n",
    "\n",
    "Your compute nodes can include GPUs. These devices are made available as FABRIC components and can be added to your nodes like any other component.\n",
    "\n",
    "This example notebook will demonstrate how to reserve and use Nvidia GPU devices on FABRIC.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup the Experiment\n",
    "\n",
    "#### Import FABRIC API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fabrictestbed_extensions.fablib.fablib import FablibManager as fablib_manager\n",
    "\n",
    "try: \n",
    "    fablib = fablib_manager()\n",
    "                     \n",
    "    fablib.show_config()\n",
    "except Exception as e:\n",
    "    print(f\"Exception: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create a Node\n",
    "\n",
    "The cell below creates a slice that contains a single node. The node includes a GPU component.\n",
    "\n",
    "### Set the Slice Name and FABRIC Site\n",
    "\n",
    "Use a filter function to find random sites with your desired GPUs.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "slice_name=\"MySlice\"\n",
    "\n",
    "rtx6000_site = fablib.get_random_site(filter_function=lambda x: x['rtx6000_available'] > 0)\n",
    "tesla_site = fablib.get_random_site(filter_function=lambda x: x['tesla_t4_available'] > 0)                                                                                                                                                                                                                          \n",
    "\n",
    "rtx6000_node_name='rtx1'\n",
    "tesla_node_name='tesla1'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    #Create Slice\n",
    "    slice = fablib.new_slice(name=slice_name)\n",
    "\n",
    "    # Add node\n",
    "    rtx_node = slice.add_node(name=rtx6000_node_name, site=rtx6000_site)\n",
    "    rtx_node.add_component(model='GPU_RTX6000', name='gpu1')\n",
    "\n",
    "    tesla_node = slice.add_node(name=tesla_node_name, site=tesla_site)\n",
    "    tesla_node.add_component(model='GPU_TeslaT4', name='gpu1')\n",
    "\n",
    "\n",
    "    #Submit Slice Request\n",
    "    slice.submit()\n",
    "except Exception as e:\n",
    "    print(f\"Exception: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get the Slice\n",
    "\n",
    "Retrieve the node information and save the management IP addresses."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    slice = fablib.get_slice(name=slice_name)\n",
    "    slice.show()\n",
    "except Exception as e:\n",
    "    print(f\"Exception: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get the Nodes\n",
    "\n",
    "Retrieve the nodes information and save the management IP address.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    rtx_node = slice.get_node(rtx6000_node_name) \n",
    "    rtx_node.show()\n",
    "    \n",
    "    rtx_gpu = rtx_node.get_component('gpu1')\n",
    "    rtx_gpu.show()\n",
    "    \n",
    "    tesla_node = slice.get_node(tesla_node_name) \n",
    "    tesla_node.show()\n",
    "    \n",
    "    tesla_gpu = tesla_node.get_component('gpu1')\n",
    "    tesla_gpu.show()\n",
    "except Exception as e:\n",
    "    print(f\"Exception: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use the RTX6000 Node for the rest of the example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "node = rtx_node"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GPU PCI Device\n",
    "\n",
    "Run the command <code>lspci</code> to see your GPU PCI device(s). This is the raw GPU PCI device that is not yet configured for use.  You can use the GPUs as you would any GPUs.\n",
    "\n",
    "View node1's GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "command = \"sudo dnf install -q -y pciutils && lspci | grep 'NVIDIA\\|3D controller'\"\n",
    "try:\n",
    "    stdout, stderr = node.execute(command)\n",
    "except Exception as e:\n",
    "    print(f\"Exception: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Install Nvidia Drivers\n",
    "\n",
    "Now, let's run the following commands to install the latest CUDA driver and the CUDA libraries and compiler."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "commands = [\n",
    "    'sudo dnf install -q -y epel-release',\n",
    "    'sudo dnf config-manager --add-repo https://developer.download.nvidia.com/compute/cuda/repos/rhel8/x86_64/cuda-rhel8.repo',\n",
    "    'sudo dnf install -q -y kernel-devel kernel-headers nvidia-driver nvidia-settings cuda-driver cuda'\n",
    "]\n",
    "try:\n",
    "    print(\"Installing CUDA...\")\n",
    "    for command in commands:\n",
    "        stdout, stderr = node.execute(command)\n",
    "    print(\"Done installing CUDA. Now, reboot for the changes to take effect.\")\n",
    "except Exception as e:\n",
    "    print(f\"Fail: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And once CUDA is installed, reboot the machine."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reboot = 'sudo reboot'\n",
    "try:\n",
    "    print(reboot)\n",
    "    node.execute(reboot)\n",
    "    \n",
    "    slice.wait_ssh(timeout=360,interval=10,progress=True)\n",
    "\n",
    "    print(\"Now testing SSH abilites to reconnect...\",end=\"\")\n",
    "    slice.update()\n",
    "    slice.test_ssh()\n",
    "    print(\"Reconnected!\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"Fail: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing the GPU and CUDA Installation\n",
    "\n",
    "First, verify that the Nvidia drivers recognize the GPU by running `nvidia-smi`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    stdout, stderr = node.execute(\"nvidia-smi\")\n",
    "    print(f\"stdout: {stdout}\")\n",
    "except Exception as e:\n",
    "    print(f\"Exception: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's upload the following \"Hello World\" CUDA program file to the node.\n",
    "\n",
    "`hello-world.cu`\n",
    "\n",
    "*Source: https://computer-graphics.se/multicore/pdf/hello-world.cu*\n",
    "\n",
    "*Author: Ingemar Ragnemalm*\n",
    "\n",
    ">This file is from *\"The real \"Hello World!\" for CUDA, OpenCL and GLSL!\"* (https://computer-graphics.se/hello-world-for-cuda.html), written by Ingemar Ragnemalm, programmer and CUDA teacher. The only changes (if you download the original file from the website) are to additionally `#include <unistd.h>`, as `sleep()` is now a fuction defined in the `unistd.h` library."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "node.upload_file('./hello-world.cu', 'hello-world.cu')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now compile the `.cu` file using `nvcc`, the CUDA compiler tool installed with CUDA. In this example, we create an executable called `hello_world`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    stdout, stderr = node.execute(\"/usr/local/cuda-11.7/bin/nvcc -o hello_world hello-world.cu\")\n",
    "except Exception as e:\n",
    "    print(f\"Exception: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, run the executable:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    stdout, stderr = node.execute(\"./hello_world\")\n",
    "    print(f\"stdout: {stdout}\")\n",
    "except Exception as e:\n",
    "    print(f\"Exception: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you see `Hello World!`, the CUDA program ran successfully. `World!` was computed on the GPU from an array of offsets being summed with the string `Hello `, and the resut was printed to stdout.\n",
    "\n",
    "### Congratulations! You have now successfully run a program on a FABRIC GPU!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cleanup Your Experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    slice = fablib.get_slice(name=slice_name)\n",
    "    slice.delete()\n",
    "except Exception as e:\n",
    "    print(f\"Exception: {e}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
